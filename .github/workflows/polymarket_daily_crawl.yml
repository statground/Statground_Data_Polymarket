name: Polymarket Daily Crawl (events/markets/series)

on:
  schedule:
    # every day at 00:25 UTC (09:25 KST)
    - cron: "25 0 * * *"
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: polymarket-daily-crawl
  cancel-in-progress: false

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Run incremental crawler
        env:
          # Set this per-repo:
          # - Year repos: "2026"
          # - Main repo (null bucket): leave empty
          TARGET_MODE: "year"
          TARGET_YEAR: "2026"
          PAGE_LIMIT: "100"
          MAX_PAGES: "200"
          SLEEP_SEC: "0.25"
        run: |
          python scripts/crawl_polymarket_incremental.py

      - name: Git status
        run: |
          git status --porcelain

      - name: Commit changes (if any)
        run: |
          set -e
          if [ -z "$(git status --porcelain)" ]; then
            echo "No changes."
            exit 0
          fi
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "Daily Polymarket crawl"

      - name: Push
        run: |
          # If your org blocks GITHUB_TOKEN writes, replace this with a PAT secret:
          # git remote set-url origin https://x-access-token:${{ secrets.POLYMARKET_PUSH_TOKEN }}@github.com/${{ github.repository }}
          git push
