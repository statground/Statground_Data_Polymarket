name: Polymarket hourly scheduler (daily crawl + hourly stats, single workflow)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 * * * *"   # every hour at HH:00 UTC

concurrency:
  group: polymarket-hourly-scheduler
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout orchestrator repo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.POLYMARKET_PAT }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Decide (daily crawl?) then run stats (always)
        env:
          ORG: "statground"
          REPO_PREFIX: "Statground_Data_Polymarket"
          ORCHESTRATOR_REPO: "Statground_Data_Polymarket"
          DEFAULT_BRANCH: "main"
          GH_PAT: ${{ secrets.POLYMARKET_PAT }}

          # Crawl settings
          POLY_BASE: "https://gamma-api.polymarket.com"
          PAGE_LIMIT: "100"
          MAX_PAGES: "200"
          ORDER_PRIMARY: "updatedAt"
          ORDER_FALLBACK: "id"
          OUT_ROOT: "by_created"
          STATE_PATH: ".state/polymarket_checkpoint.json"

          # Scheduler settings
          SCHED_STATE_PATH: ".state/polymarket_scheduler.json"
          CRAWL_ONCE_PER_UTC_DAY: "true"

          # Stats settings (your existing stats script should read these, if applicable)
          REPO_STATS_MD_PATH: "POLYMARKET_REPO_STATS.md"
        run: |
          python scripts/polymarket_hourly_scheduler.py
